{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spoken Language Recognition Using Convolutional Neural Networks\n",
    "\n",
    "_written by Joscha S. Rieber (Fraunhofer IAIS) in 2020_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset preparation\n",
    "\n",
    "Please go to the [Mozilla Common Voice Website](https://commonvoice.mozilla.org/) and download the full German and English datasets. In the following scripts we will thin out the datasets to make them more handy and play with the data.\n",
    "* Download German and English datasets\n",
    "* Extract them\n",
    "* Define paths below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = 'train'\n",
    "test = 'test'\n",
    "\n",
    "eng = 'english'\n",
    "ger = 'german'\n",
    "\n",
    "languages = [eng, ger]\n",
    "categories = [train, test]\n",
    "\n",
    "original_dataset_paths = {}\n",
    "\n",
    "original_dataset_paths[eng] = '/data/jrieber/IFINDER-2143/common-voice/cv-corpus-5.1-2020-06-22/en/' # TODO: Adapt this folder!\n",
    "original_dataset_paths[ger] = '/data/jrieber/IFINDER-2143/common-voice/cv-corpus-5.1-2020-06-22/de/' # TODO: Adapt this folder!\n",
    "\n",
    "target_root_path = '../data/'\n",
    "\n",
    "num_files_to_take_for_each_language = 20000\n",
    "train_rate = 0.8  # Use 80 % of the data for training and the rest for testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check paths\n",
    "\n",
    "If something goes wrong here, check paths again and read the documentation of the GitHub repository and check how to set-up your environment correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "for lang in languages:\n",
    "    if not os.path.isdir(original_dataset_paths[lang]):\n",
    "        raise\n",
    "    for category in categories:\n",
    "        if not os.path.isdir(target_root_path + category + '/' + lang):\n",
    "            raise\n",
    "\n",
    "for lang in languages:\n",
    "    if not os.path.isfile(original_dataset_paths[lang] + 'validated.tsv'):\n",
    "        raise\n",
    "    if not os.path.isdir(original_dataset_paths[lang] + 'clips'):\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect only num_files_to_take_for_each_language files which duration is between 7.5 and 10 seconds\n",
    "\n",
    "<span style=\"color:red\">Note, that this process might take many hours!</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If this goes wrong, check your environment and read the documentation\n",
    "\n",
    "import librosa as lr\n",
    "from glob import glob\n",
    "from random import shuffle\n",
    "from shutil import copy2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def copy_audio_files_for_language(lang):\n",
    "    \n",
    "    print('')\n",
    "    print('Copying files for language ' + lang + '...')\n",
    "    print('')\n",
    "    \n",
    "    # Only take validated speech data\n",
    "    df = pd.read_csv(original_dataset_paths[lang] + 'validated.tsv', sep='\\t')\n",
    "    all_filenames = df['path'].tolist()\n",
    "    shuffle(all_filenames)\n",
    "    \n",
    "    counter = 0\n",
    "    \n",
    "    category = train    \n",
    "    \n",
    "    # Process files\n",
    "    for filename in all_filenames:\n",
    "        file = original_dataset_paths[lang] + 'clips/' + filename\n",
    "        try:\n",
    "            audio_segment, sample_rate = lr.load(file)\n",
    "            if np.count_nonzero(audio_segment) == 0:\n",
    "                raise Exception('Audio is silent!')\n",
    "            if audio_segment.ndim != 1:\n",
    "                raise Exception('Audio signal has wrong number of dimensions: ' + str(audio_segment.ndim))\n",
    "            duration_sec = lr.core.get_duration(audio_segment, sr=sample_rate)\n",
    "        except Exception as e:\n",
    "            print('WARNING! Error while loading file \\\"' + file + '\\\": ' + str(e) + ' - Skipping...')\n",
    "            continue\n",
    "        \n",
    "        # Only copy audio files with a certain minimum duration\n",
    "        if 7.5 < duration_sec < 10.0:\n",
    "            copy2(file, target_root_path + category + '/' + lang)\n",
    "            counter += 1\n",
    "        \n",
    "        # Stop after collecting enough files\n",
    "        if counter == int(num_files_to_take_for_each_language * train_rate):\n",
    "            category = test\n",
    "        if counter == num_files_to_take_for_each_language:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy files to create the German language train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Copying files for language german...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "warnings.simplefilter('ignore', UserWarning)\n",
    "\n",
    "copy_audio_files_for_language(ger)\n",
    "\n",
    "warnings.simplefilter('default', UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy files to create the English language train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Copying files for language english...\n",
      "\n",
      "WARNING! Error while loading file \"/data/jrieber/IFINDER-2143/common-voice/cv-corpus-5.1-2020-06-22/en/clips/common_voice_en_190149.mp3\": Audio is silent! - Skipping...\n"
     ]
    }
   ],
   "source": [
    "warnings.simplefilter('ignore', UserWarning)\n",
    "\n",
    "copy_audio_files_for_language(eng)\n",
    "\n",
    "warnings.simplefilter('default', UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check number of collected files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay!\n"
     ]
    }
   ],
   "source": [
    "for category in categories:\n",
    "    \n",
    "    if category == train:\n",
    "        num_files = int(num_files_to_take_for_each_language * train_rate)\n",
    "    else:\n",
    "        num_files = int(num_files_to_take_for_each_language * (1.0 - train_rate))\n",
    "        \n",
    "    for lang in languages:\n",
    "        folder = target_root_path + category + '/' + lang + '/'\n",
    "        all_files = glob(folder + '*.mp3')\n",
    "        \n",
    "        if len(all_files) < (num_files - 1):\n",
    "            raise Exception('Folder \\\"' + folder + '\\\" only contains ' + str(len(all_files)) + ' files instead of ' + str(num_files) + '!')\n",
    "            \n",
    "print('Okay!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now make yourself familiar with the dataset by listening to some of the files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total duration of english train is 37.0 h\n",
      "Total duration of german train is 37.0 h\n",
      "Total duration of english test is 9.2 h\n",
      "Total duration of german test is 9.3 h\n"
     ]
    }
   ],
   "source": [
    "warnings.simplefilter('ignore', UserWarning)\n",
    "\n",
    "for category in categories:\n",
    "    for lang in languages:\n",
    "        duration_sec = 0.0\n",
    "        \n",
    "        folder = target_root_path + category + '/' + lang + '/'\n",
    "        all_files = glob(folder + '*.mp3')\n",
    "        \n",
    "        for file in all_files:\n",
    "            duration_sec += lr.core.get_duration(filename=file)\n",
    "            \n",
    "        duration_h = duration_sec / 60.0 / 60.0\n",
    "        print('Total duration of ' + lang + ' ' + category + ' is ' + str(round(duration_h, 1)) + ' h')\n",
    "        \n",
    "warnings.simplefilter('default', UserWarning)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
