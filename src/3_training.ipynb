{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language-Recognition using ConvNets\n",
    "\n",
    "_written by Joscha S. Rieber (Fraunhofer IAIS) in 2020_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = 'train'\n",
    "test = 'test'\n",
    "\n",
    "eng = 'english'\n",
    "ger = 'german'\n",
    "\n",
    "languages = [eng, ger]\n",
    "categories = [train, test]\n",
    "\n",
    "dataset_root_path = '../data/'\n",
    "train_path = dataset_root_path + train\n",
    "\n",
    "batch_size = 32\n",
    "image_width = 500\n",
    "image_height = 128\n",
    "\n",
    "validation_split = 0.1\n",
    "learning_rate = 0.005\n",
    "\n",
    "model_output_file = dataset_root_path + 'model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# XLA compiles your TensorFlow graph into a sequence of GPU kernels generated specifically for your model.\n",
    "# Since these kernels are unique to your program, they can exploit model-specific information for optimization.\n",
    "\n",
    "# import os\n",
    "# os.environ['TF_XLA_FLAGS'] = '--tf_xla_cpu_global_jit'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps per Epoch: 4500\n",
      "Validation steps: 500\n"
     ]
    }
   ],
   "source": [
    "all_files = glob(train_path + '/*/*.png')\n",
    "\n",
    "num_validation = len(all_files) * validation_split\n",
    "num_train = len(all_files) - num_validation\n",
    "\n",
    "validation_steps = int(num_validation / batch_size)\n",
    "steps_per_epoch = int(num_train / batch_size)\n",
    "\n",
    "print('Steps per Epoch: ' + str(steps_per_epoch))\n",
    "print('Validation steps: ' + str(validation_steps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Batch Generator Function\n",
    "\n",
    "The following function loads the available images for training, shuffles them and serves them to Keras' training algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 144000 images belonging to 2 classes.\n",
      "Found 16000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "image_data_generator = ImageDataGenerator(rescale=1./255, validation_split=validation_split)\n",
    "train_generator = image_data_generator.flow_from_directory(train_path, batch_size=batch_size, class_mode='categorical', target_size=(image_width, image_height), color_mode='grayscale', subset='training')\n",
    "validation_generator = image_data_generator.flow_from_directory(train_path, batch_size=batch_size, class_mode='categorical', target_size=(image_width, image_height), color_mode='grayscale', subset='validation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, BatchNormalization, Input, Concatenate\n",
    "\n",
    "from tensorflow.keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization (BatchNo (None, 500, 128, 1)       4         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 500, 128, 16)      800       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 500, 128, 16)      64        \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 250, 64, 16)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 250, 64, 32)       12832     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 250, 64, 32)       128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 125, 32, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 125, 32, 64)       18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 125, 32, 64)       256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 62, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 62, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 62, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 31, 8, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 31, 8, 256)        295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 31, 8, 256)        1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 15, 4, 256)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 15360)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               7864832   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 1026      \n",
      "=================================================================\n",
      "Total params: 8,268,998\n",
      "Trainable params: 8,268,004\n",
      "Non-trainable params: 994\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(BatchNormalization(input_shape=(image_width, image_height, 1)))\n",
    "model.add(Conv2D(16, (7, 7), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Conv2D(32, (5, 5), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# from tensorflow.keras.applications import VGG16\n",
    "\n",
    "# img_input = Input(shape=(128, 500, 1))\n",
    "\n",
    "# img_conc = Concatenate(axis=3, name='input_concat')([img_input, img_input, img_input])\n",
    "\n",
    "# model = VGG16(input_tensor=img_conc, weights=None, include_top=True, classes=2)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=SGD(lr=learning_rate), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', mode='max', patience=6, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "4500/4500 [==============================] - 555s 123ms/step - loss: 0.4450 - accuracy: 0.7910 - val_loss: 0.4353 - val_accuracy: 0.8008\n",
      "Epoch 2/60\n",
      "4500/4500 [==============================] - 562s 125ms/step - loss: 0.3222 - accuracy: 0.8586 - val_loss: 0.6475 - val_accuracy: 0.7219\n",
      "Epoch 3/60\n",
      "4500/4500 [==============================] - 558s 124ms/step - loss: 0.2697 - accuracy: 0.8850 - val_loss: 0.4163 - val_accuracy: 0.8205\n",
      "Epoch 4/60\n",
      "4500/4500 [==============================] - 564s 125ms/step - loss: 0.2291 - accuracy: 0.9037 - val_loss: 0.4503 - val_accuracy: 0.8069\n",
      "Epoch 5/60\n",
      "4500/4500 [==============================] - 562s 125ms/step - loss: 0.1933 - accuracy: 0.9202 - val_loss: 0.4259 - val_accuracy: 0.8189\n",
      "Epoch 6/60\n",
      "4500/4500 [==============================] - 563s 125ms/step - loss: 0.1551 - accuracy: 0.9380 - val_loss: 0.5663 - val_accuracy: 0.7943\n",
      "Epoch 7/60\n",
      "4500/4500 [==============================] - 562s 125ms/step - loss: 0.1179 - accuracy: 0.9539 - val_loss: 0.5120 - val_accuracy: 0.8258\n",
      "Epoch 8/60\n",
      "4500/4500 [==============================] - 563s 125ms/step - loss: 0.0830 - accuracy: 0.9686 - val_loss: 0.6298 - val_accuracy: 0.8095\n",
      "Epoch 9/60\n",
      "4500/4500 [==============================] - 562s 125ms/step - loss: 0.0567 - accuracy: 0.9793 - val_loss: 0.6270 - val_accuracy: 0.8151\n",
      "Epoch 10/60\n",
      "4500/4500 [==============================] - 561s 125ms/step - loss: 0.0373 - accuracy: 0.9868 - val_loss: 0.9325 - val_accuracy: 0.7807\n",
      "Epoch 11/60\n",
      "4500/4500 [==============================] - 560s 125ms/step - loss: 0.0223 - accuracy: 0.9932 - val_loss: 0.9837 - val_accuracy: 0.7958\n",
      "Epoch 12/60\n",
      "4500/4500 [==============================] - 560s 124ms/step - loss: 0.0154 - accuracy: 0.9955 - val_loss: 0.7577 - val_accuracy: 0.8215\n",
      "Epoch 13/60\n",
      "4500/4500 [==============================] - 560s 125ms/step - loss: 0.0102 - accuracy: 0.9972 - val_loss: 0.8666 - val_accuracy: 0.8200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f75c7851710>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_generator, validation_data=validation_generator, epochs=60, steps_per_epoch=steps_per_epoch, validation_steps=validation_steps, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(model_output_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
